{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMBQiRGjLEt0gP4obcepRG0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/venkata55s/ai-agents/blob/main/clip2-summarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NXbZa8U2bMVZ"
      },
      "outputs": [],
      "source": [
        "# 1 - Import required libraries\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2 - Initialize tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"t5-base\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-base\")"
      ],
      "metadata": {
        "id": "BuEbDiZcbobp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_text(text):\n",
        "  # Step 2: Tokenize the input text\n",
        "  # Add a directive prompt \"summarize: Focus on key impacts and industries:\" to guide the model for better summarization.\n",
        "  # Tokenize the text, convert it to PyTorch tensors, and truncate it to a maximum length of 512 tokens if necessary.\n",
        "  inputs = tokenizer.encode(\n",
        "      \"summarize: Focus on key impacts and industries: \" + text,\n",
        "      return_tensors=\"pt\",\n",
        "      max_length=512,\n",
        "      truncation=True\n",
        "  )\n",
        "\n",
        "  # Step 3: Generate a summary\n",
        "  # Generate a summary from the model using specific parameters:\n",
        "  # max_length: Limit the summary to a maximum of 40 tokens to keep it concise.\n",
        "  # min_length: Ensure the summary is at least 10 tokens long.\n",
        "  # length_penalty: Penalize longer outputs to prioritize brevity.\n",
        "  # num_beams: Use beam search with 5 beams for higher-quality text generation.\n",
        "  # early_stopping: Stop generation early when an acceptable output is found.\n",
        "  outputs = model.generate(\n",
        "      inputs,\n",
        "      max_length=40,\n",
        "      min_length=10,\n",
        "      length_penalty=3.5,\n",
        "      num_beams=5,\n",
        "      early_stopping=True\n",
        "  )\n",
        "\n",
        "  # Step 4: Decode the model output\n",
        "  # Decode the generated tokens back into human-readable text and remove special tokens (e.g., <pad>, <eos>).\n",
        "  summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "  # Step 5: Post-process the summary\n",
        "  # Deduplicate sentences in the summary to improve clarity and readability.\n",
        "  unique_sentences = list(dict.fromkeys(summary.split(\". \")))\n",
        "  return \". \".join(unique_sentences)"
      ],
      "metadata": {
        "id": "ntmbfqUlb6hg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "  # Step 6: Define the input text\n",
        "  # Provide a sample text to summarize.\n",
        "  sample_text = (\n",
        "      \"Artificial intelligence is a rapidly growing field that involves the creation of \"\n",
        "      \"intelligent machines capable of performing tasks that typically require human intelligence. \"\n",
        "      \"It is being used in various industries, including healthcare, finance, and transportation, \"\n",
        "      \"to improve efficiency and solve complex problems.\"\n",
        "  )\n",
        "\n",
        "  # Step 7: Generate and print the summary\n",
        "  # Call the summarize_text function with the sample text and print the original text and its summary.\n",
        "  print(\"Original Text:\")\n",
        "  print(sample_text)\n",
        "  print(\"\\nSummary:\")\n",
        "  print(summarize_text(sample_text))"
      ],
      "metadata": {
        "id": "9_iUeV1NecgZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}